{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovery of Writing Differences - Huggingface Transformers\n",
    "\n",
    "Capstone project by Tomo Umer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tomoumerdotcom.files.wordpress.com/2022/04/cropped-pho_logo_notext.png\" style=\"width:400px;height:400px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import special\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next chunk was for using the 50 books per author. Results were ... ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03 is the one with limit 50 books per author\n",
    "# library_select = pd.read_pickle('../data/library_select03.pkl')\n",
    "\n",
    "# since hugging face only accepts up to 512 characters with this model,\n",
    "# better to get words from the middle of the book\n",
    "# library_select['book_content_modified'] = library_select['book_content'].apply(lambda text: text[len(text) // 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 5 books per author\n",
    "library_select = pd.read_pickle('../data/library_fixed_author_five.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_authors = list(library_select['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many parts of a book to take\n",
    "n_parts = 10 # previous was 5\n",
    "\n",
    "bookpart_list = []\n",
    "\n",
    "for i in range(n_parts):\n",
    "    # note: the +1s are there because I don't want the exact beginning, or the end of the book (there could be some junk there)\n",
    "    bookpart_list.append(library_select['book_content'].apply(lambda text: text[(i+1)* len(text) // (n_parts+1):]))\n",
    "\n",
    "# copy the library n_parts times, to concatenate with the split texts\n",
    "library_select_multi = pd.concat([library_select]*n_parts, ignore_index=True).drop(columns='book_content')\n",
    "\n",
    "# add the above parts of the text into a new column\n",
    "library_select_multi['book_part'] = pd.concat(bookpart_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 14)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_select_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# library_select['book_length'] = library_select['book_content'].str.len()\n",
    "#library_select_multi['book_part_length'] = library_select_multi['book_part'].str.len()\n",
    "\n",
    "# and then to verify that it's the same book - 105 is of course with 21 authors, 5 books each\n",
    "# library_select_multi.loc[0]\n",
    "# library_select_multi.loc[105]\n",
    "# library_select_multi.loc[210]\n",
    "\n",
    "# library_select['author_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'bert-base-uncased'\n",
    "model_path = '../models/bert_base_uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note truncation side and padding side are to determine which side to cutoff - beginning (left) or end (rigt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, truncation_side='right', padding_side='right')\n",
    "\n",
    "def tokenize_function(df):\n",
    "    return tokenizer(df['text'], truncation=True, padding='max_length',  max_length=512)\n",
    "\n",
    "acc = evaluate.load('accuracy') #average = None\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "mcc = evaluate.load('matthews_correlation')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc_m = acc.compute(predictions=predictions, references=labels)\n",
    "    precision_m = precision.compute(predictions=predictions, average = 'macro', references=labels) #used  weighted for 50 books\n",
    "    recall_m = recall.compute(predictions=predictions, average = 'macro', references=labels)\n",
    "    f1_m = f1.compute(predictions=predictions, average = 'macro', references=labels)\n",
    "    mcc_m = mcc.compute(predictions=predictions, references=labels)\n",
    "    metrics = {\n",
    "        'accuracy': acc_m['accuracy'],\n",
    "        'precision': precision_m['precision'],\n",
    "        'recall': recall_m['recall'],\n",
    "        'f1': f1_m['f1'],\n",
    "        'mcc': mcc_m['matthews_correlation']\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this part is the same if I use library_select ..\n",
    "# select_authors = list(library_select_multi.sort_values(by='authorcentury')['author'].unique())\n",
    "\n",
    "# authors_to_num = {select_authors[i]: i for i in range(len(select_authors))}\n",
    "# num_to_authors = {v: k for k, v in authors_to_num.items()}\n",
    "\n",
    "# library_select_multi['author_num'] = library_select_multi['author'].map(authors_to_num)\n",
    "#authors_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = library_select_multi[['book_part']]\n",
    "y = library_select_multi['author_num']\n",
    "\n",
    "X_part, X_test, y_part, y_test = train_test_split(X, y, test_size=0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use for validation first\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_part, y_part, test_size=0.15, random_state = 42, stratify = y_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train further into train & 15% for validation (replace test here with validation)\n",
    "train_ds = Dataset.from_dict({'text': X_train['book_part'], 'labels': y_train})\n",
    "val_ds = Dataset.from_dict({'text': X_val['book_part'], 'labels': y_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006ea644e1eb436d9381961167fc702c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/714 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_ds = train_ds.map(tokenize_function)\n",
    "tokenized_train_ds = tokenized_train_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65024fae2e974864b77db1a164d91994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_val_ds = val_ds.map(tokenize_function)\n",
    "tokenized_val_ds = tokenized_val_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# this needs to change if I change num authors\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "# this is only needed if running the trainer locally\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=15, #10 with last model\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    use_mps_device=True,\n",
    "    save_total_limit=15, #10 with last model\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    log_level ='info',\n",
    "    metric_for_best_model='eval_mcc',\n",
    "    optim = 'adamw_torch',\n",
    "    learning_rate=1e-05,\n",
    "    #fp16=True #this is to run on the gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this if uncommented to run the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 714\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 675\n",
      "  Number of trainable parameters = 109,498,389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be041d3ee74441958a6f22133391adb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/675 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 # only run this on google collab, it takes 4 hours on my laptop!</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2 trainer.train()                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/tomoumer/opt/anaconda3/envs/huggingface_ds6/lib/python3.11/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tra</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">iner.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1645</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1647 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1648 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/tomoumer/opt/anaconda3/envs/huggingface_ds6/lib/python3.11/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tra</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">iner.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1943</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1940 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1942 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> is_torch_tpu_available()                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1943 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> (torch.isnan(tr_loss_step) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> torch.isinf(tr_loss_step))          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1944 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>):                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1945 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># if loss is nan or inf simply add the average of previous logged lo</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1946 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss += tr_loss / (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> + <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.global_step - <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._globalstep_  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m2\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[2m# only run this on google collab, it takes 4 hours on my laptop!\u001b[0m                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2 trainer.train()                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/tomoumer/opt/anaconda3/envs/huggingface_ds6/lib/python3.11/site-packages/transformers/\u001b[0m\u001b[1;33mtra\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33miner.py\u001b[0m:\u001b[94m1645\u001b[0m in \u001b[92mtrain\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1642 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1643 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1644 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1645 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1646 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1647 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1648 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/tomoumer/opt/anaconda3/envs/huggingface_ds6/lib/python3.11/site-packages/transformers/\u001b[0m\u001b[1;33mtra\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33miner.py\u001b[0m:\u001b[94m1943\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1940 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1942 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m is_torch_tpu_available()                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1943 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[95mand\u001b[0m (torch.isnan(tr_loss_step) \u001b[95mor\u001b[0m torch.isinf(tr_loss_step))          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1944 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m):                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1945 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# if loss is nan or inf simply add the average of previous logged lo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1946 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mtr_loss += tr_loss / (\u001b[94m1\u001b[0m + \u001b[96mself\u001b[0m.state.global_step - \u001b[96mself\u001b[0m._globalstep_  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only run this on google collab, it takes 4 hours on my laptop!\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking the pretrained model from google collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/bert_base_uncased/fivebooks_tenparts/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"../models/bert_base_uncased/fivebooks_tenparts/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../models/bert_base_uncased/fivebooks_tenparts/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/bert_base_uncased/fivebooks_tenparts/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#model = AutoModelForSequenceClassification.from_pretrained(model_path + '/checkpoint-58362')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('../models/bert_base_uncased/fivebooks_tenparts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found safetensors installation, but --save_safetensors=False. Safetensors should be a preferred weights saving format due to security and performance reasons. If your model cannot be saved by safetensors please feel free to open an issue at https://github.com/huggingface/safetensors!\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "test_args = TrainingArguments(\n",
    "    output_dir= '../models/bert_base_uncased/fivebooks_tenparts/',\n",
    "    do_train=False,\n",
    "    do_predict=True,\n",
    "    use_mps_device=True,\n",
    "    per_device_eval_batch_size=4,\n",
    "    # fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=test_args,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b758e64cd6c44bcb89e56064ce3c6372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = Dataset.from_dict({'text': X_test['book_part'], 'labels': y_test})\n",
    "\n",
    "tokenized_test_ds = test_ds.map(tokenize_function)\n",
    "tokenized_test_ds = tokenized_test_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 210\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3d17b560754494892e24263dfc90df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.predict(tokenized_test_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.003623127937317,\n",
       " 'test_accuracy': 0.8476190476190476,\n",
       " 'test_precision': 0.8654880133871731,\n",
       " 'test_recall': 0.8476190476190475,\n",
       " 'test_f1': 0.8468330589368478,\n",
       " 'test_mcc': 0.8411423259760178,\n",
       " 'test_runtime': 422.9781,\n",
       " 'test_samples_per_second': 0.496,\n",
       " 'test_steps_per_second': 0.125}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.46653876, -0.18904889, -1.4445355 , ...,  1.1178238 ,\n",
       "         3.0759544 ,  0.6864331 ],\n",
       "       [-1.2339908 ,  2.6362147 ,  0.8099453 , ...,  0.7417352 ,\n",
       "        -0.31717333, -0.48127759],\n",
       "       [ 0.20771548, -0.4811055 , -0.6417899 , ..., -0.8276385 ,\n",
       "         1.4266744 ,  0.5450225 ],\n",
       "       ...,\n",
       "       [-1.1972811 ,  0.22819383, -0.6620481 , ...,  3.7477772 ,\n",
       "         0.31357872,  0.5382277 ],\n",
       "       [-1.1369017 ,  0.17825049, -0.64254266, ...,  3.7398863 ,\n",
       "         0.04298076,  0.2895866 ],\n",
       "       [ 0.12475164,  0.3906656 , -0.20289129, ..., -0.88842905,\n",
       "         0.5512589 , -0.52083534]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  1, 13, 20, 15, 10,  9,  0,  2, 11,  0,  0, 18, 13, 17,  2,  5,\n",
       "        9,  2,  8, 17,  3,  5,  1, 10, 19, 19,  3,  1, 16, 12,  6, 11,  0,\n",
       "       19, 10, 11,  8, 19, 14,  1, 20,  1,  2,  9, 20,  4,  2, 12,  2,  9,\n",
       "       12, 17,  8,  7,  6,  1, 19,  7,  2, 15,  8, 10, 14,  3,  6,  2, 12,\n",
       "       14,  4, 13, 17, 13,  8,  5, 20, 14,  3, 11,  2, 15, 19, 18, 18, 15,\n",
       "       15, 19,  4,  8,  5, 10, 18, 12,  5,  3, 18,  7, 15,  2, 17,  2, 17,\n",
       "       10, 16,  7, 12, 16, 13,  6, 20, 20, 20, 20, 20,  4,  4, 11,  4, 15,\n",
       "       10, 10, 15, 15, 10, 12, 15, 15, 17,  6,  5, 13, 17, 20, 13,  0, 19,\n",
       "        9,  7, 14,  9,  7, 15,  6,  0, 16,  3,  4,  4,  0, 18,  2,  4, 12,\n",
       "       14,  6, 12,  8, 16, 11, 18,  5,  6,  7,  6, 20, 11,  0,  2,  1,  3,\n",
       "        8,  9,  0,  2,  9, 17,  2,  3,  1, 10,  1, 12, 11, 16,  3,  0, 19,\n",
       "       16,  7,  6,  9, 11, 16, 10,  9, 17, 17,  3, 15, 18,  1, 18, 10,  3,\n",
       "        2, 14,  2, 18, 18, 15])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to get which labels are being predicted\n",
    "results.predictions.argmax(axis=1)\n",
    "\n",
    "# this simply stores the correct predictions, so equivalent to y_test:\n",
    "# results.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_authors = list(library_select['author'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/hf_testppred.pkl', 'wb') as f:\n",
    "#      pickle.dump([y_test, results.predictions.argmax(axis=1), results.metrics], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Predicted Label: %{x}<br>True Label: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "Homer",
          "Confucius",
          "Plato",
          "Cicero, Marcus Tullius",
          "Seneca, Lucius Annaeus",
          "Dante Alighieri",
          "Boccaccio, Giovanni",
          "Machiavelli, Niccolò",
          "Shakespeare, William",
          "Molière",
          "Austen, Jane",
          "Defoe, Daniel",
          "Jefferson, Thomas",
          "Dickens, Charles",
          "Doyle, Arthur Conan",
          "Dumas, Alexandre",
          "Twain, Mark",
          "Churchill, Winston",
          "Dick, Philip K.",
          "Huxley, Aldous",
          "Lovecraft, H. P. (Howard Phillips)"
         ],
         "xaxis": "x",
         "y": [
          "Homer",
          "Confucius",
          "Plato",
          "Cicero, Marcus Tullius",
          "Seneca, Lucius Annaeus",
          "Dante Alighieri",
          "Boccaccio, Giovanni",
          "Machiavelli, Niccolò",
          "Shakespeare, William",
          "Molière",
          "Austen, Jane",
          "Defoe, Daniel",
          "Jefferson, Thomas",
          "Dickens, Charles",
          "Doyle, Arthur Conan",
          "Dumas, Alexandre",
          "Twain, Mark",
          "Churchill, Winston",
          "Dick, Philip K.",
          "Huxley, Aldous",
          "Lovecraft, H. P. (Howard Phillips)"
         ],
         "yaxis": "y",
         "z": [
          [
           9,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           3,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           2,
           6,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           1,
           1,
           7,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           9,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           4,
           0,
           0,
           0,
           0,
           6,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           1,
           0,
           0,
           0,
           2,
           0,
           0,
           0,
           7,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           9,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           8,
           0,
           0,
           1,
           0,
           0,
           1,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           2,
           0,
           0,
           7,
           0,
           0,
           1,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           7,
           1,
           0,
           1,
           0,
           0,
           1
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           1,
           7,
           1,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           9,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(209, 238, 234)"
          ],
          [
           0.16666666666666666,
           "rgb(168, 219, 217)"
          ],
          [
           0.3333333333333333,
           "rgb(133, 196, 201)"
          ],
          [
           0.5,
           "rgb(104, 171, 184)"
          ],
          [
           0.6666666666666666,
           "rgb(79, 144, 166)"
          ],
          [
           0.8333333333333334,
           "rgb(59, 115, 143)"
          ],
          [
           1,
           "rgb(42, 86, 116)"
          ]
         ],
         "showscale": false
        },
        "height": 800,
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Predicted Label"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "True Label"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.imshow(confusion_matrix(y_test, results.predictions.argmax(axis=1)),\n",
    "                width=1000,\n",
    "                height=800,\n",
    "                text_auto=True,\n",
    "                labels=dict(x='Predicted Label',\n",
    "                            y='True Label'),\n",
    "                            x=select_authors,\n",
    "                            y=select_authors,\n",
    "                            color_continuous_scale='Teal'\n",
    "                            )\n",
    "\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing New Text\n",
    "\n",
    "This part will ideally be in an app where any text can be uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtext = pd.DataFrame()\n",
    "\n",
    "for book_num, book_name in enumerate(['Lambda', 'Deathway']):\n",
    "        filepath = f'../data/{book_name} by Tomo Umer.txt'\n",
    "\n",
    "        with open(filepath, encoding = 'utf-8') as fi:\n",
    "                book = fi.read()\n",
    "        \n",
    "        tmp_text = pd.DataFrame({'id': f'TU{str(book_num).zfill(3)}',\n",
    "                                 'title': [book_name],\n",
    "                                 'author': 'Umer, Tomo',\n",
    "                                 'authorcentury': 21,\n",
    "                                 'book_content': [book]})\n",
    "\n",
    "        newtext = pd.concat([newtext, tmp_text], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookpart_list = []\n",
    "\n",
    "for i in range(n_parts):\n",
    "    # note: the +1s are there because I don't want the exact beginning, or the end of the book (there could be some junk there)\n",
    "    bookpart_list.append(newtext['book_content'].apply(lambda text: text[(i+1)* len(text) // (n_parts+1):]))\n",
    "\n",
    "# copy the library n_parts times, to concatenate with the split texts\n",
    "newtext_multi = pd.concat([newtext]*n_parts, ignore_index=True).drop(columns='book_content')\n",
    "\n",
    "# add the above parts of the text into a new column\n",
    "newtext_multi['book_part'] = pd.concat(bookpart_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ee52c422c44a0fb42dc6c2d1f82a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "newtext_ds = Dataset.from_dict({'text': newtext_multi['book_part']}) #, 'labels': y_test})\n",
    "\n",
    "tokenized_newtext_ds= newtext_ds.map(tokenize_function)\n",
    "tokenized_newtext_ds = tokenized_newtext_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 20\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fda0de6083454c82166c9a65af443a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_results = trainer.predict(tokenized_newtext_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first book Lambda, second Deathway\n",
    "# newtext_multi['title'].unique()\n",
    "\n",
    "# to see what got predicted\n",
    "# new_results.predictions.argmax(axis=1)\n",
    "\n",
    "# book1_authors = set(new_results.predictions.argmax(axis=1)[::2])\n",
    "# book2_authors = set(new_results.predictions.argmax(axis=1)[1::2])\n",
    "\n",
    "# for author in book1_authors:\n",
    "#     print('Lambda is similar in writing to: ', num_to_authors[author])\n",
    "\n",
    "# for author in book2_authors:\n",
    "#     print('Deathway is similar in writing to: ', num_to_authors[author])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed for the strmlite app\n",
    "authors_df = pd.read_pickle('../data/select_authors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_winners(model_predictions_max):\n",
    "    unique_num, counts = np.unique(model_predictions_max, return_counts=True)\n",
    "\n",
    "    unique_authors = [authors_df.loc[authors_df['author_num'] == unique, 'author'].iloc[0] for unique in unique_num]\n",
    "\n",
    "    return pd.DataFrame({'most likely author': unique_authors, 'number of times':counts})\n",
    "\n",
    "# Note that the above is because I put two books in at once. for one at a time, I would define this function\n",
    "# to just give it predictions - like so\n",
    "# def compute_winners(model_predictions):\n",
    "#     unique_num, counts = np.unique(model_predictions.argmax(axis=1), return_counts=True)\n",
    "\n",
    "#     unique_authors = [num_to_authors[unique] for unique in unique_num]\n",
    "\n",
    "#     return pd.DataFrame({'most likely author': unique_authors, 'number of times':counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "book1_winners = compute_winners(new_results.predictions.argmax(axis=1)[::2])\n",
    "book2_winners = compute_winners(new_results.predictions.argmax(axis=1)[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most likely author</th>\n",
       "      <th>number of times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dick, Philip K.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovecraft, H. P. (Howard Phillips)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   most likely author  number of times\n",
       "0                     Dick, Philip K.                6\n",
       "1  Lovecraft, H. P. (Howard Phillips)                4"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book2_winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 21)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results.predictions.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the results are logits. Need to use softmax to convert them to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.nn.functional as F\n",
    "# new_probabilities = F.softmax(new_results, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_probabilities = special.softmax(new_results.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_probabilities_df = pd.DataFrame(new_probabilities, columns=select_authors).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homer                     0.90%\n",
       "Confucius                 2.16%\n",
       "Plato                     0.95%\n",
       "Cicero, Marcus Tullius    1.56%\n",
       "Seneca, Lucius Annaeus    1.06%\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_probabilities_df[0].head().map('{:.2%}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dick, Philip K.                       55.24%\n",
      "Doyle, Arthur Conan                   12.07%\n",
      "Lovecraft, H. P. (Howard Phillips)     3.95%\n",
      "Huxley, Aldous                         2.96%\n",
      "Molière                                2.96%\n",
      "Name: 0, dtype: object\n",
      "Dick, Philip K.                       33.01%\n",
      "Lovecraft, H. P. (Howard Phillips)    11.93%\n",
      "Doyle, Arthur Conan                   10.78%\n",
      "Molière                                7.92%\n",
      "Huxley, Aldous                         4.58%\n",
      "Name: 1, dtype: object\n",
      "Dick, Philip K.                       37.43%\n",
      "Doyle, Arthur Conan                   17.24%\n",
      "Lovecraft, H. P. (Howard Phillips)     6.61%\n",
      "Churchill, Winston                     5.55%\n",
      "Huxley, Aldous                         4.70%\n",
      "Name: 2, dtype: object\n",
      "Dick, Philip K.                       55.30%\n",
      "Doyle, Arthur Conan                    7.31%\n",
      "Lovecraft, H. P. (Howard Phillips)     5.30%\n",
      "Molière                                4.87%\n",
      "Churchill, Winston                     2.93%\n",
      "Name: 3, dtype: object\n",
      "Dick, Philip K.                       36.96%\n",
      "Doyle, Arthur Conan                   11.60%\n",
      "Lovecraft, H. P. (Howard Phillips)     6.85%\n",
      "Huxley, Aldous                         4.69%\n",
      "Churchill, Winston                     4.31%\n",
      "Name: 4, dtype: object\n",
      "Dick, Philip K.                       19.78%\n",
      "Lovecraft, H. P. (Howard Phillips)    15.77%\n",
      "Huxley, Aldous                        13.70%\n",
      "Doyle, Arthur Conan                   10.04%\n",
      "Molière                                6.00%\n",
      "Name: 5, dtype: object\n",
      "Dick, Philip K.                       31.95%\n",
      "Doyle, Arthur Conan                   15.39%\n",
      "Huxley, Aldous                         8.52%\n",
      "Lovecraft, H. P. (Howard Phillips)     7.10%\n",
      "Molière                                4.33%\n",
      "Name: 6, dtype: object\n",
      "Dick, Philip K.                       23.76%\n",
      "Doyle, Arthur Conan                   15.71%\n",
      "Lovecraft, H. P. (Howard Phillips)    10.79%\n",
      "Molière                                7.02%\n",
      "Churchill, Winston                     5.83%\n",
      "Name: 7, dtype: object\n",
      "Dick, Philip K.                       47.02%\n",
      "Doyle, Arthur Conan                    9.71%\n",
      "Huxley, Aldous                         5.15%\n",
      "Dumas, Alexandre                       4.69%\n",
      "Lovecraft, H. P. (Howard Phillips)     4.00%\n",
      "Name: 8, dtype: object\n",
      "Lovecraft, H. P. (Howard Phillips)    34.64%\n",
      "Huxley, Aldous                        10.90%\n",
      "Dick, Philip K.                        8.31%\n",
      "Molière                                5.49%\n",
      "Doyle, Arthur Conan                    4.49%\n",
      "Name: 9, dtype: object\n",
      "Dick, Philip K.                       43.72%\n",
      "Doyle, Arthur Conan                   14.37%\n",
      "Molière                                5.75%\n",
      "Lovecraft, H. P. (Howard Phillips)     4.91%\n",
      "Churchill, Winston                     3.39%\n",
      "Name: 10, dtype: object\n",
      "Lovecraft, H. P. (Howard Phillips)    11.37%\n",
      "Dick, Philip K.                       10.69%\n",
      "Huxley, Aldous                         9.65%\n",
      "Dickens, Charles                       9.17%\n",
      "Twain, Mark                            7.09%\n",
      "Name: 11, dtype: object\n",
      "Dick, Philip K.                       32.21%\n",
      "Doyle, Arthur Conan                   13.68%\n",
      "Lovecraft, H. P. (Howard Phillips)     6.71%\n",
      "Churchill, Winston                     5.21%\n",
      "Huxley, Aldous                         4.31%\n",
      "Name: 12, dtype: object\n",
      "Lovecraft, H. P. (Howard Phillips)    14.67%\n",
      "Dick, Philip K.                       13.51%\n",
      "Doyle, Arthur Conan                   12.91%\n",
      "Churchill, Winston                     7.51%\n",
      "Twain, Mark                            6.16%\n",
      "Name: 13, dtype: object\n",
      "Dick, Philip K.        45.93%\n",
      "Doyle, Arthur Conan     7.95%\n",
      "Huxley, Aldous          6.44%\n",
      "Dumas, Alexandre        5.12%\n",
      "Molière                 4.26%\n",
      "Name: 14, dtype: object\n",
      "Dick, Philip K.                       46.79%\n",
      "Doyle, Arthur Conan                   14.83%\n",
      "Lovecraft, H. P. (Howard Phillips)     4.84%\n",
      "Churchill, Winston                     4.60%\n",
      "Molière                                3.83%\n",
      "Name: 15, dtype: object\n",
      "Dick, Philip K.        25.03%\n",
      "Doyle, Arthur Conan    11.45%\n",
      "Huxley, Aldous          6.49%\n",
      "Dickens, Charles        6.00%\n",
      "Dumas, Alexandre        5.87%\n",
      "Name: 16, dtype: object\n",
      "Dick, Philip K.                       30.75%\n",
      "Lovecraft, H. P. (Howard Phillips)    15.03%\n",
      "Doyle, Arthur Conan                   11.04%\n",
      "Huxley, Aldous                         5.01%\n",
      "Molière                                4.68%\n",
      "Name: 17, dtype: object\n",
      "Dick, Philip K.        26.01%\n",
      "Doyle, Arthur Conan    17.45%\n",
      "Dumas, Alexandre        8.46%\n",
      "Churchill, Winston      5.60%\n",
      "Dickens, Charles        4.66%\n",
      "Name: 18, dtype: object\n",
      "Lovecraft, H. P. (Howard Phillips)    17.38%\n",
      "Dick, Philip K.                       14.01%\n",
      "Doyle, Arthur Conan                   12.69%\n",
      "Churchill, Winston                     8.34%\n",
      "Molière                                5.92%\n",
      "Name: 19, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for column in new_probabilities_df:\n",
    "    print(new_probabilities_df[column].sort_values(ascending=False).head().map('{:.2%}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_books = pd.concat([newtext_multi ,pd.DataFrame(new_probabilities, columns=select_authors)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authorcentury</th>\n",
       "      <th>book_part</th>\n",
       "      <th>Homer</th>\n",
       "      <th>Confucius</th>\n",
       "      <th>Plato</th>\n",
       "      <th>Cicero, Marcus Tullius</th>\n",
       "      <th>Seneca, Lucius Annaeus</th>\n",
       "      <th>...</th>\n",
       "      <th>Defoe, Daniel</th>\n",
       "      <th>Jefferson, Thomas</th>\n",
       "      <th>Dickens, Charles</th>\n",
       "      <th>Doyle, Arthur Conan</th>\n",
       "      <th>Dumas, Alexandre</th>\n",
       "      <th>Twain, Mark</th>\n",
       "      <th>Churchill, Winston</th>\n",
       "      <th>Dick, Philip K.</th>\n",
       "      <th>Huxley, Aldous</th>\n",
       "      <th>Lovecraft, H. P. (Howard Phillips)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>in the world left in her at that precise momen...</td>\n",
       "      <td>0.011767</td>\n",
       "      <td>0.033306</td>\n",
       "      <td>0.020630</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>0.028561</td>\n",
       "      <td>0.024702</td>\n",
       "      <td>0.107751</td>\n",
       "      <td>0.014644</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>0.035008</td>\n",
       "      <td>0.330138</td>\n",
       "      <td>0.045839</td>\n",
       "      <td>0.119293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>rily lie down. “Just a quick break,” she told ...</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.027308</td>\n",
       "      <td>0.013429</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.008419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009009</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.015575</td>\n",
       "      <td>0.073071</td>\n",
       "      <td>0.012141</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.029301</td>\n",
       "      <td>0.552963</td>\n",
       "      <td>0.027216</td>\n",
       "      <td>0.053041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>ing up with her laundry.\\nAt the very least, h...</td>\n",
       "      <td>0.013791</td>\n",
       "      <td>0.028952</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>0.041455</td>\n",
       "      <td>0.100375</td>\n",
       "      <td>0.023001</td>\n",
       "      <td>0.034004</td>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.197822</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>0.157733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>t to miss this party of yours.”\\nThat last com...</td>\n",
       "      <td>0.015013</td>\n",
       "      <td>0.040081</td>\n",
       "      <td>0.027520</td>\n",
       "      <td>0.013259</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016293</td>\n",
       "      <td>0.033778</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.157088</td>\n",
       "      <td>0.014020</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.058297</td>\n",
       "      <td>0.237623</td>\n",
       "      <td>0.045027</td>\n",
       "      <td>0.107924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>ing mind games with her on this particular Thu...</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.020951</td>\n",
       "      <td>0.021341</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.010446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024458</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.039557</td>\n",
       "      <td>0.044855</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.040883</td>\n",
       "      <td>0.042861</td>\n",
       "      <td>0.083092</td>\n",
       "      <td>0.108967</td>\n",
       "      <td>0.346388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     title      author  authorcentury  \\\n",
       "1  TU001  Deathway  Umer, Tomo             21   \n",
       "3  TU001  Deathway  Umer, Tomo             21   \n",
       "5  TU001  Deathway  Umer, Tomo             21   \n",
       "7  TU001  Deathway  Umer, Tomo             21   \n",
       "9  TU001  Deathway  Umer, Tomo             21   \n",
       "\n",
       "                                           book_part     Homer  Confucius  \\\n",
       "1  in the world left in her at that precise momen...  0.011767   0.033306   \n",
       "3  rily lie down. “Just a quick break,” she told ...  0.009384   0.027308   \n",
       "5  ing up with her laundry.\\nAt the very least, h...  0.013791   0.028952   \n",
       "7  t to miss this party of yours.”\\nThat last com...  0.015013   0.040081   \n",
       "9  ing mind games with her on this particular Thu...  0.016578   0.020951   \n",
       "\n",
       "      Plato  Cicero, Marcus Tullius  Seneca, Lucius Annaeus  ...  \\\n",
       "1  0.020630                0.009636                0.011020  ...   \n",
       "3  0.013429                0.012603                0.008419  ...   \n",
       "5  0.017620                0.015480                0.011818  ...   \n",
       "7  0.027520                0.013259                0.010393  ...   \n",
       "9  0.021341                0.007261                0.010446  ...   \n",
       "\n",
       "   Defoe, Daniel  Jefferson, Thomas  Dickens, Charles  Doyle, Arthur Conan  \\\n",
       "1       0.014073           0.028561          0.024702             0.107751   \n",
       "3       0.009009           0.020250          0.015575             0.073071   \n",
       "5       0.014141           0.028479          0.041455             0.100375   \n",
       "7       0.016293           0.033778          0.026798             0.157088   \n",
       "9       0.024458           0.033863          0.039557             0.044855   \n",
       "\n",
       "   Dumas, Alexandre  Twain, Mark  Churchill, Winston  Dick, Philip K.  \\\n",
       "1          0.014644     0.031148            0.035008         0.330138   \n",
       "3          0.012141     0.026211            0.029301         0.552963   \n",
       "5          0.023001     0.034004            0.037762         0.197822   \n",
       "7          0.014020     0.036364            0.058297         0.237623   \n",
       "9          0.013498     0.040883            0.042861         0.083092   \n",
       "\n",
       "   Huxley, Aldous  Lovecraft, H. P. (Howard Phillips)  \n",
       "1        0.045839                            0.119293  \n",
       "3        0.027216                            0.053041  \n",
       "5        0.136993                            0.157733  \n",
       "7        0.045027                            0.107924  \n",
       "9        0.108967                            0.346388  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar_books.loc[similar_books['title'] == 'Lambda'].head()\n",
    "similar_books.loc[similar_books['title'] == 'Deathway'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_books = (\n",
    "    similar_books\n",
    "        .drop(columns=['id', 'authorcentury', 'book_part', 'author'])\n",
    "        .groupby('title')\n",
    "        .mean()\n",
    "        .pivot_table(columns='title')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dick, Philip K.                       0.255924\n",
      "Lovecraft, H. P. (Howard Phillips)    0.141731\n",
      "Doyle, Arthur Conan                   0.106840\n",
      "Huxley, Aldous                        0.063496\n",
      "Molière                               0.054452\n",
      "Name: Deathway, dtype: float32\n",
      "--------\n",
      "Dick, Philip K.                       0.381491\n",
      "Doyle, Arthur Conan                   0.130887\n",
      "Lovecraft, H. P. (Howard Phillips)    0.054233\n",
      "Huxley, Aldous                        0.050893\n",
      "Dumas, Alexandre                      0.041248\n",
      "Name: Lambda, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(similar_books.sort_values(by='Deathway', ascending=False)['Deathway'].head())\n",
    "print('--------')\n",
    "print(similar_books.sort_values(by='Lambda', ascending=False)['Lambda'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_ds6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
