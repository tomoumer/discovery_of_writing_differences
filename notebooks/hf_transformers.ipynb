{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovery of Writing Differences - Huggingface Transformers\n",
    "\n",
    "Capstone project by Tomo Umer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tomoumerdotcom.files.wordpress.com/2022/04/cropped-pho_logo_notext.png\" alt=\"PRAISE DOG\" style=\"width:400px;height:400px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next chunk was for using the 50 books per author. Results were ... ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03 is the one with limit 50 books per author\n",
    "# library_select = pd.read_pickle('../data/library_select03.pkl')\n",
    "\n",
    "# since hugging face only accepts up to 512 characters with this model,\n",
    "# better to get words from the middle of the book\n",
    "# library_select['book_content_modified'] = library_select['book_content'].apply(lambda text: text[len(text) // 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 5 books per author\n",
    "library_select = pd.read_pickle('../data/library_select_5perauthor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many parts of a book to take\n",
    "n_parts = 10 # previous was 5\n",
    "\n",
    "bookpart_list = []\n",
    "\n",
    "for i in range(n_parts):\n",
    "    # note: the +1s are there because I don't want the exact beginning, or the end of the book (there could be some junk there)\n",
    "    bookpart_list.append(library_select['book_content'].apply(lambda text: text[(i+1)* len(text) // (n_parts+1):]))\n",
    "\n",
    "# copy the library n_parts times, to concatenate with the split texts\n",
    "library_select_multi = pd.concat([library_select]*n_parts, ignore_index=True).drop(columns='book_content')\n",
    "\n",
    "# add the above parts of the text into a new column\n",
    "library_select_multi['book_part'] = pd.concat(bookpart_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# library_select['book_length'] = library_select['book_content'].str.len()\n",
    "#library_select_multi['book_part_length'] = library_select_multi['book_part'].str.len()\n",
    "\n",
    "# and then to verify that it's the same book - 105 is of course with 21 authors, 5 books each\n",
    "# library_select_multi.loc[0]\n",
    "# library_select_multi.loc[105]\n",
    "# library_select_multi.loc[210]\n",
    "\n",
    "# library_select['author_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'bert-base-uncased'\n",
    "model_path = '../data/bert_base_uncased_fivepart'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note truncation side and padding side are to determine which side to cutoff - beginning (left) or end (rigt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, truncation_side='right', padding_side='right')\n",
    "\n",
    "def tokenize_function(df):\n",
    "    return tokenizer(df['text'], truncation=True, padding='max_length',  max_length=512)\n",
    "\n",
    "acc = evaluate.load('accuracy') #average = None\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "mcc = evaluate.load('matthews_correlation')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc_m = acc.compute(predictions=predictions, references=labels)\n",
    "    precision_m = precision.compute(predictions=predictions, average = 'macro', references=labels) #used  weighted for 50 books\n",
    "    recall_m = recall.compute(predictions=predictions, average = 'macro', references=labels)\n",
    "    f1_m = f1.compute(predictions=predictions, average = 'macro', references=labels)\n",
    "    mcc_m = mcc.compute(predictions=predictions, references=labels)\n",
    "    metrics = {\n",
    "        'accuracy': acc_m['accuracy'],\n",
    "        'precision': precision_m['precision'],\n",
    "        'recall': recall_m['recall'],\n",
    "        'f1': f1_m['f1'],\n",
    "        'mcc': mcc_m['matthews_correlation']\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is the same if I use library_select ..\n",
    "select_authors = list(library_select_multi.sort_values(by='authorcentury')['author'].unique())\n",
    "\n",
    "authors_to_num = {select_authors[i]: i for i in range(len(select_authors))}\n",
    "num_to_authors = {v: k for k, v in authors_to_num.items()}\n",
    "\n",
    "library_select_multi['author_num'] = library_select_multi['author'].map(authors_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part is not\n",
    "#X = library_select[['book_part']]\n",
    "#y = library_select['author_num']\n",
    "\n",
    "X = library_select_multi[['book_part']]\n",
    "y = library_select_multi['author_num']\n",
    "\n",
    "X_part, X_test, y_part, y_test = train_test_split(X, y, test_size=0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use for validation first\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_part, y_part, test_size=0.15, random_state = 42, stratify = y_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train further into train & 15% for validation (replace test here with validation)\n",
    "#train_ds = Dataset.from_dict({'text': X_train['book_content'], 'labels': LabelBinarizer().fit_transform(y_train['author_num'])})\n",
    "#val_ds = Dataset.from_dict({'text': X_test['book_content'], 'labels': LabelBinarizer().fit_transform(y_test['author_num'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train further into train & 15% for validation (replace test here with validation)\n",
    "train_ds = Dataset.from_dict({'text': X_train['book_part'], 'labels': y_train})\n",
    "val_ds = Dataset.from_dict({'text': X_val['book_part'], 'labels': y_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7474bf2ae0d74ab791ca602935a23e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/714 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_ds = train_ds.map(tokenize_function)\n",
    "tokenized_train_ds = tokenized_train_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e98b0722e349d28885667e6edd5b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/126 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_val_ds = val_ds.map(tokenize_function)\n",
    "tokenized_val_ds = tokenized_val_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# this needs to change if I change num authors\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=15, #10 with last model\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_total_limit=15, #10 with last model\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    log_level ='info',\n",
    "    metric_for_best_model='eval_mcc',\n",
    "    optim = 'adamw_torch',\n",
    "    learning_rate=1e-05,\n",
    "    #fp16=True #this is to run on the gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this if uncommented to run the trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_train_ds,\n",
    "#     eval_dataset=tokenized_val_ds,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this on google collab, it takes 4 hours on my laptop!\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=AutoModelForSequenceClassification.from_pretrained('../models/books5_parts10_epochs20/', num_labels=21),\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelBinarizer().fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3e20ad8f8c45f9b9b90f3e5054053f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = Dataset.from_dict({'text': X_test['book_part'], 'labels': y_test})\n",
    "\n",
    "tokenized_test_ds = test_ds.map(tokenize_function)\n",
    "tokenized_test_ds = tokenized_test_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 210\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3531486d905c4a1e9f4eca48eac46b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.predict(tokenized_test_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.747704803943634,\n",
       " 'test_accuracy': 0.8523809523809524,\n",
       " 'test_precision': 0.8709528566671423,\n",
       " 'test_recall': 0.8523809523809524,\n",
       " 'test_f1': 0.8499490192027161,\n",
       " 'test_mcc': 0.8464927558247427,\n",
       " 'test_runtime': 139.4928,\n",
       " 'test_samples_per_second': 1.505,\n",
       " 'test_steps_per_second': 0.1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2970257 , -0.99485993, -0.57020867, ..., -0.6852048 ,\n",
       "         3.7632456 , -0.81379783],\n",
       "       [-0.6107387 ,  4.588185  ,  0.04168364, ...,  0.14784265,\n",
       "        -0.7315902 , -0.45718578],\n",
       "       [-0.67458475, -0.21007276, -0.8315575 , ...,  1.8761536 ,\n",
       "        -0.7537751 ,  1.2979146 ],\n",
       "       ...,\n",
       "       [-0.87162113,  0.06329876, -0.8780149 , ...,  3.6599357 ,\n",
       "         0.17955273,  0.91381323],\n",
       "       [-0.34778407, -0.07626636, -0.7778298 , ...,  3.6431763 ,\n",
       "        -0.50725883,  1.8426869 ],\n",
       "       [-0.8960496 , -0.77703226, -0.78770393, ..., -0.23276825,\n",
       "         2.7416377 , -0.9668989 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  1, 13, 20, 12, 10,  9,  8,  7, 11,  0,  0, 18, 13, 16,  2,  5,\n",
       "        9,  7,  8, 17,  3,  5,  1, 10, 19, 19,  3,  1, 16,  4,  6, 11,  0,\n",
       "       19, 10, 11,  8, 19, 14,  1, 14,  1,  7,  9, 20,  4,  2, 12,  2,  9,\n",
       "       12, 17,  6,  7,  6,  1, 19,  7,  2, 15,  8, 10, 14,  5,  6,  3, 12,\n",
       "       14,  8, 13, 17, 13,  8,  5, 20, 14,  3, 11,  2, 17, 19, 18, 18, 15,\n",
       "       15, 19,  4,  8,  5, 10, 18, 12,  5,  3, 18,  5, 15,  3, 17,  2, 17,\n",
       "       10, 16,  7, 16, 16, 13,  6, 20, 20, 20, 20, 20,  5,  4, 11,  4, 15,\n",
       "       13, 10, 14, 16, 10, 12, 15, 15, 17,  6,  5, 13, 17, 20, 13,  0, 19,\n",
       "        9,  7, 14,  9,  7, 15, 11,  0, 13,  3,  4,  4,  0, 18,  2,  8, 12,\n",
       "       14,  6, 12,  8, 16, 11, 18,  5,  6,  4,  6, 20, 11,  0,  7,  1,  4,\n",
       "        8,  9,  0,  2,  9, 14,  2,  3,  1, 13,  1, 12, 11, 16,  3,  0, 19,\n",
       "       16,  7,  6,  9, 11, 16, 10,  9, 17, 17,  4, 15, 18,  1, 12, 10,  0,\n",
       "        3, 14,  2, 18, 18, 15])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to get which labels are being predicted\n",
    "results.predictions.argmax(axis=1).shape\n",
    "\n",
    "# this simply stores the correct predictions, so equivalent to y_test:\n",
    "# results.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Predicted Label: %{x}<br>True Label: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "Homer",
          "Confucius",
          "Plato",
          "Cicero, Marcus Tullius",
          "Seneca, Lucius Annaeus",
          "Dante Alighieri",
          "Boccaccio, Giovanni",
          "Machiavelli, Niccolò",
          "Shakespeare, William",
          "Molière",
          "Jefferson, Thomas",
          "Defoe, Daniel",
          "Austen, Jane",
          "Twain, Mark",
          "Doyle, Arthur Conan",
          "Dickens, Charles",
          "Dumas, Alexandre",
          "Dick, Philip K.",
          "Lovecraft, H. P. (Howard Phillips)",
          "Huxley, Aldous",
          "Churchill, Winston"
         ],
         "xaxis": "x",
         "y": [
          "Homer",
          "Confucius",
          "Plato",
          "Cicero, Marcus Tullius",
          "Seneca, Lucius Annaeus",
          "Dante Alighieri",
          "Boccaccio, Giovanni",
          "Machiavelli, Niccolò",
          "Shakespeare, William",
          "Molière",
          "Jefferson, Thomas",
          "Defoe, Daniel",
          "Austen, Jane",
          "Twain, Mark",
          "Doyle, Arthur Conan",
          "Dickens, Charles",
          "Dumas, Alexandre",
          "Dick, Philip K.",
          "Lovecraft, H. P. (Howard Phillips)",
          "Huxley, Aldous",
          "Churchill, Winston"
         ],
         "yaxis": "y",
         "z": [
          [
           9,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           6,
           3,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           1,
           8,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           5,
           3,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0
          ],
          [
           0,
           0,
           0,
           0,
           1,
           7,
           1,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           9,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           9,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           8,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           8,
           0,
           0,
           1,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           7,
           0,
           0,
           0,
           2,
           0,
           1
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           7,
           0,
           0,
           0,
           1,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           9,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           9
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(209, 238, 234)"
          ],
          [
           0.16666666666666666,
           "rgb(168, 219, 217)"
          ],
          [
           0.3333333333333333,
           "rgb(133, 196, 201)"
          ],
          [
           0.5,
           "rgb(104, 171, 184)"
          ],
          [
           0.6666666666666666,
           "rgb(79, 144, 166)"
          ],
          [
           0.8333333333333334,
           "rgb(59, 115, 143)"
          ],
          [
           1,
           "rgb(42, 86, 116)"
          ]
         ],
         "showscale": false
        },
        "height": 800,
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Predicted Label"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "True Label"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.imshow(confusion_matrix(y_test, results.predictions.argmax(axis=1)),\n",
    "                width=1000,\n",
    "                height=800,\n",
    "                text_auto=True,\n",
    "                labels=dict(x='Predicted Label',\n",
    "                            y='True Label'),\n",
    "                            x=select_authors,\n",
    "                            y=select_authors,\n",
    "                            color_continuous_scale='Teal'\n",
    "                            )\n",
    "\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing New Text\n",
    "\n",
    "This part will ideally be in an app where any text can be uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtext = pd.DataFrame()\n",
    "\n",
    "for book_num, book_name in enumerate(['Lambda', 'Deathway']):\n",
    "        filepath = f'../data/{book_name} by Tomo Umer.txt'\n",
    "\n",
    "        with open(filepath, encoding = 'utf-8') as fi:\n",
    "                book = fi.read()\n",
    "        \n",
    "        tmp_text = pd.DataFrame({'id': f'TU{str(book_num).zfill(3)}',\n",
    "                                 'title': [book_name],\n",
    "                                 'author': 'Umer, Tomo',\n",
    "                                 'authorcentury': 21,\n",
    "                                 'book_content': [book]})\n",
    "\n",
    "        newtext = pd.concat([newtext, tmp_text], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookpart_list = []\n",
    "\n",
    "for i in range(n_parts):\n",
    "    # note: the +1s are there because I don't want the exact beginning, or the end of the book (there could be some junk there)\n",
    "    bookpart_list.append(newtext['book_content'].apply(lambda text: text[(i+1)* len(text) // (n_parts+1):]))\n",
    "\n",
    "# copy the library n_parts times, to concatenate with the split texts\n",
    "newtext_multi = pd.concat([newtext]*n_parts, ignore_index=True).drop(columns='book_content')\n",
    "\n",
    "# add the above parts of the text into a new column\n",
    "newtext_multi['book_part'] = pd.concat(bookpart_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a7a2b4d3684d5c8614991d41183eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "newtext_ds = Dataset.from_dict({'text': newtext_multi['book_part']}) #, 'labels': y_test})\n",
    "\n",
    "tokenized_newtext_ds= newtext_ds.map(tokenize_function)\n",
    "tokenized_newtext_ds = tokenized_newtext_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 20\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9b80769c894b77866d04eccb1c97af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_results = trainer.predict(tokenized_newtext_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first book Lambda, second Deathway\n",
    "# newtext_multi['title'].unique()\n",
    "\n",
    "# to see what got predicted\n",
    "# new_results.predictions.argmax(axis=1)\n",
    "\n",
    "book1_authors = set(new_results.predictions.argmax(axis=1)[::2])\n",
    "book2_authors = set(new_results.predictions.argmax(axis=1)[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda is similar in writing to:  Dick, Philip K.\n",
      "Lambda is similar in writing to:  Huxley, Aldous\n",
      "Deathway is similar in writing to:  Dick, Philip K.\n",
      "Deathway is similar in writing to:  Lovecraft, H. P. (Howard Phillips)\n",
      "Deathway is similar in writing to:  Huxley, Aldous\n"
     ]
    }
   ],
   "source": [
    "for author in book1_authors:\n",
    "    print('Lambda is similar in writing to: ', num_to_authors[author])\n",
    "\n",
    "for author in book2_authors:\n",
    "    print('Deathway is similar in writing to: ', num_to_authors[author])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Homer',\n",
       " 'Confucius',\n",
       " 'Plato',\n",
       " 'Cicero, Marcus Tullius',\n",
       " 'Seneca, Lucius Annaeus',\n",
       " 'Dante Alighieri',\n",
       " 'Boccaccio, Giovanni',\n",
       " 'Machiavelli, Niccolò',\n",
       " 'Shakespeare, William',\n",
       " 'Molière',\n",
       " 'Jefferson, Thomas',\n",
       " 'Defoe, Daniel',\n",
       " 'Austen, Jane',\n",
       " 'Twain, Mark',\n",
       " 'Doyle, Arthur Conan',\n",
       " 'Dickens, Charles',\n",
       " 'Dumas, Alexandre',\n",
       " 'Dick, Philip K.',\n",
       " 'Lovecraft, H. P. (Howard Phillips)',\n",
       " 'Huxley, Aldous',\n",
       " 'Churchill, Winston']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_books = pd.concat([newtext_multi ,pd.DataFrame(new_results.predictions, columns=select_authors)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_books = (\n",
    "    similar_books\n",
    "        .drop(columns=['id', 'authorcentury', 'book_part', 'author'])\n",
    "        .groupby('title')\n",
    "        .mean()\n",
    "        .pivot_table(columns='title')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lovecraft, H. P. (Howard Phillips)    2.386379\n",
      "Dick, Philip K.                       2.149984\n",
      "Austen, Jane                          1.299474\n",
      "Huxley, Aldous                        1.048226\n",
      "Dickens, Charles                      0.654352\n",
      "Name: Deathway, dtype: float32\n",
      "--------\n",
      "Dick, Philip K.                       2.738583\n",
      "Huxley, Aldous                        1.723177\n",
      "Lovecraft, H. P. (Howard Phillips)    1.312014\n",
      "Austen, Jane                          0.757156\n",
      "Dickens, Charles                      0.749532\n",
      "Name: Lambda, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(similar_books.sort_values(by='Deathway', ascending=False)['Deathway'].head())\n",
    "print('--------')\n",
    "print(similar_books.sort_values(by='Lambda', ascending=False)['Lambda'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_ds6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
