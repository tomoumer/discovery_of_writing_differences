{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discovery of Writing Differences - Huggingface Transformers\n",
    "\n",
    "Capstone project by Tomo Umer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://tomoumerdotcom.files.wordpress.com/2022/04/cropped-pho_logo_notext.png\" style=\"width:400px;height:400px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import special\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next chunk was for using the 50 books per author. Results were ... ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03 is the one with limit 50 books per author\n",
    "# library_select = pd.read_pickle('../data/library_select03.pkl')\n",
    "\n",
    "# since hugging face only accepts up to 512 characters with this model,\n",
    "# better to get words from the middle of the book\n",
    "# library_select['book_content_modified'] = library_select['book_content'].apply(lambda text: text[len(text) // 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 5 books per author\n",
    "library_select = pd.read_pickle('../data/library_fixed_author_five.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many parts of a book to take\n",
    "n_parts = 10 # previous was 5\n",
    "\n",
    "bookpart_list = []\n",
    "\n",
    "for i in range(n_parts):\n",
    "    # note: the +1s are there because I don't want the exact beginning, or the end of the book (there could be some junk there)\n",
    "    bookpart_list.append(library_select['book_content'].apply(lambda text: text[(i+1)* len(text) // (n_parts+1):]))\n",
    "\n",
    "# copy the library n_parts times, to concatenate with the split texts\n",
    "library_select_multi = pd.concat([library_select]*n_parts, ignore_index=True).drop(columns='book_content')\n",
    "\n",
    "# add the above parts of the text into a new column\n",
    "library_select_multi['book_part'] = pd.concat(bookpart_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050, 13)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library_select_multi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for testing\n",
    "# library_select['book_length'] = library_select['book_content'].str.len()\n",
    "#library_select_multi['book_part_length'] = library_select_multi['book_part'].str.len()\n",
    "\n",
    "# and then to verify that it's the same book - 105 is of course with 21 authors, 5 books each\n",
    "# library_select_multi.loc[0]\n",
    "# library_select_multi.loc[105]\n",
    "# library_select_multi.loc[210]\n",
    "\n",
    "# library_select['author_num'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'bert-base-uncased'\n",
    "model_path = '../models/bert_base_uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note truncation side and padding side are to determine which side to cutoff - beginning (left) or end (rigt)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, truncation_side='right', padding_side='right')\n",
    "\n",
    "def tokenize_function(df):\n",
    "    return tokenizer(df['text'], truncation=True, padding='max_length',  max_length=512)\n",
    "\n",
    "acc = evaluate.load('accuracy') #average = None\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "mcc = evaluate.load('matthews_correlation')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc_m = acc.compute(predictions=predictions, references=labels)\n",
    "    precision_m = precision.compute(predictions=predictions, average = 'macro', references=labels) #used  weighted for 50 books\n",
    "    recall_m = recall.compute(predictions=predictions, average = 'macro', references=labels)\n",
    "    f1_m = f1.compute(predictions=predictions, average = 'macro', references=labels)\n",
    "    mcc_m = mcc.compute(predictions=predictions, references=labels)\n",
    "    metrics = {\n",
    "        'accuracy': acc_m['accuracy'],\n",
    "        'precision': precision_m['precision'],\n",
    "        'recall': recall_m['recall'],\n",
    "        'f1': f1_m['f1'],\n",
    "        'mcc': mcc_m['matthews_correlation']\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this part is the same if I use library_select ..\n",
    "select_authors = list(library_select_multi.sort_values(by='authorcentury')['author'].unique())\n",
    "\n",
    "authors_to_num = {select_authors[i]: i for i in range(len(select_authors))}\n",
    "num_to_authors = {v: k for k, v in authors_to_num.items()}\n",
    "\n",
    "library_select_multi['author_num'] = library_select_multi['author'].map(authors_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Homer': 0,\n",
       " 'Confucius': 1,\n",
       " 'Plato': 2,\n",
       " 'Cicero, Marcus Tullius': 3,\n",
       " 'Seneca, Lucius Annaeus': 4,\n",
       " 'Dante Alighieri': 5,\n",
       " 'Boccaccio, Giovanni': 6,\n",
       " 'Machiavelli, Niccolò': 7,\n",
       " 'Shakespeare, William': 8,\n",
       " 'Molière': 9,\n",
       " 'Jefferson, Thomas': 10,\n",
       " 'Defoe, Daniel': 11,\n",
       " 'Austen, Jane': 12,\n",
       " 'Twain, Mark': 13,\n",
       " 'Doyle, Arthur Conan': 14,\n",
       " 'Dickens, Charles': 15,\n",
       " 'Dumas, Alexandre': 16,\n",
       " 'Dick, Philip K.': 17,\n",
       " 'Lovecraft, H. P. (Howard Phillips)': 18,\n",
       " 'Huxley, Aldous': 19,\n",
       " 'Churchill, Winston': 20}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = library_select_multi[['book_part']]\n",
    "y = library_select_multi['author_num']\n",
    "\n",
    "X_part, X_test, y_part, y_test = train_test_split(X, y, test_size=0.2, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use for validation first\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_part, y_part, test_size=0.15, random_state = 42, stratify = y_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train further into train & 15% for validation (replace test here with validation)\n",
    "train_ds = Dataset.from_dict({'text': X_train['book_part'], 'labels': y_train})\n",
    "val_ds = Dataset.from_dict({'text': X_val['book_part'], 'labels': y_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_ds = train_ds.map(tokenize_function)\n",
    "tokenized_train_ds = tokenized_train_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_val_ds = val_ds.map(tokenize_function)\n",
    "tokenized_val_ds = tokenized_val_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this needs to change if I change num authors\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is only needed if running the trainer locally\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path,\n",
    "    evaluation_strategy='epoch',\n",
    "    num_train_epochs=15, #10 with last model\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_total_limit=15, #10 with last model\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    log_level ='info',\n",
    "    metric_for_best_model='eval_mcc',\n",
    "    optim = 'adamw_torch',\n",
    "    learning_rate=1e-05,\n",
    "    #fp16=True #this is to run on the gpu\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this if uncommented to run the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_ds,\n",
    "    eval_dataset=tokenized_val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this on google collab, it takes 4 hours on my laptop!\n",
    "# trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking the pretrained model from google collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = AutoModelForSequenceClassification.from_pretrained(model_path + '/checkpoint-58362')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('../models/bert_base_uncased/fivebooks_tenparts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_args = TrainingArguments(\n",
    "    output_dir= '../models/bert_base_uncased/fivebooks_tenparts/',\n",
    "    do_train=False,\n",
    "    do_predict=True,\n",
    "    per_device_eval_batch_size=4,\n",
    "    # fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=test_args,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc500e466084b77b14ed0a4ee8801f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/210 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_ds = Dataset.from_dict({'text': X_test['book_part'], 'labels': y_test})\n",
    "\n",
    "tokenized_test_ds = test_ds.map(tokenize_function)\n",
    "tokenized_test_ds = tokenized_test_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7918c79ee11648c4968bf4806ebc85c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = trainer.predict(tokenized_test_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.747704803943634,\n",
       " 'test_accuracy': 0.8523809523809524,\n",
       " 'test_precision': 0.8709528566671423,\n",
       " 'test_recall': 0.8523809523809524,\n",
       " 'test_f1': 0.8499490192027161,\n",
       " 'test_mcc': 0.8464927558247427,\n",
       " 'test_runtime': 135.7142,\n",
       " 'test_samples_per_second': 1.547,\n",
       " 'test_steps_per_second': 0.391}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2970259 , -0.9948605 , -0.57020885, ..., -0.6852046 ,\n",
       "         3.7632463 , -0.81379783],\n",
       "       [-0.6107386 ,  4.5881853 ,  0.04168366, ...,  0.14784263,\n",
       "        -0.73159015, -0.45718566],\n",
       "       [-0.67458504, -0.2100727 , -0.83155763, ...,  1.8761533 ,\n",
       "        -0.75377494,  1.2979147 ],\n",
       "       ...,\n",
       "       [-0.8716213 ,  0.0632986 , -0.87801504, ...,  3.6599355 ,\n",
       "         0.17955239,  0.913813  ],\n",
       "       [-0.34778407, -0.07626636, -0.7778298 , ...,  3.6431763 ,\n",
       "        -0.50725883,  1.8426869 ],\n",
       "       [-0.8960496 , -0.77703226, -0.78770393, ..., -0.23276825,\n",
       "         2.7416377 , -0.9668989 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  1, 10, 13, 12, 10,  9,  8,  7, 11,  0,  0, 18, 13, 16,  4,  0,\n",
       "        9,  7,  8, 17,  3,  5,  1,  7, 19, 19,  3,  1, 16, 10,  6, 11,  0,\n",
       "        9, 10, 11,  8,  5, 14,  1, 20,  9,  7,  9, 20,  3,  2, 12,  2,  9,\n",
       "       12, 17,  6,  7,  6,  1, 19,  7,  2, 15,  8, 10, 14,  4,  6,  3, 12,\n",
       "       14,  8, 13, 17, 13,  8,  5, 20, 14,  3, 11,  3, 17, 19, 18, 18, 12,\n",
       "       15, 19,  4,  8,  5, 10, 18, 12,  5,  3, 18,  6, 19,  3, 17,  2, 17,\n",
       "       10, 16,  7, 16, 16, 16, 11, 20, 13, 20, 20, 20,  4,  4, 11,  2, 15,\n",
       "       13, 10, 14, 16, 10, 12, 15, 11, 17,  6,  5, 13, 17, 20, 13,  0, 19,\n",
       "        9,  7, 14,  9,  7, 11, 11,  0, 16,  3,  3,  4,  0, 18,  2,  9, 12,\n",
       "       14,  6, 12,  8, 16, 11, 18,  5,  7,  4,  6, 20, 11,  0,  7,  1,  4,\n",
       "        8,  9,  0,  2,  9, 18,  2,  3,  1, 13,  1, 12, 11, 16,  3,  0, 19,\n",
       "       16,  2,  2,  9, 11, 16, 10,  9, 17, 17,  3, 15, 18,  1, 12, 10,  2,\n",
       "        2, 14,  2, 18, 18, 15])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is to get which labels are being predicted\n",
    "results.predictions.argmax(axis=1)\n",
    "\n",
    "# this simply stores the correct predictions, so equivalent to y_test:\n",
    "# results.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Predicted Label: %{x}<br>True Label: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "texttemplate": "%{z}",
         "type": "heatmap",
         "x": [
          "Homer",
          "Confucius",
          "Plato",
          "Cicero, Marcus Tullius",
          "Seneca, Lucius Annaeus",
          "Dante Alighieri",
          "Boccaccio, Giovanni",
          "Machiavelli, Niccolò",
          "Shakespeare, William",
          "Molière",
          "Jefferson, Thomas",
          "Defoe, Daniel",
          "Austen, Jane",
          "Twain, Mark",
          "Doyle, Arthur Conan",
          "Dickens, Charles",
          "Dumas, Alexandre",
          "Dick, Philip K.",
          "Lovecraft, H. P. (Howard Phillips)",
          "Huxley, Aldous",
          "Churchill, Winston"
         ],
         "xaxis": "x",
         "y": [
          "Homer",
          "Confucius",
          "Plato",
          "Cicero, Marcus Tullius",
          "Seneca, Lucius Annaeus",
          "Dante Alighieri",
          "Boccaccio, Giovanni",
          "Machiavelli, Niccolò",
          "Shakespeare, William",
          "Molière",
          "Jefferson, Thomas",
          "Defoe, Daniel",
          "Austen, Jane",
          "Twain, Mark",
          "Doyle, Arthur Conan",
          "Dickens, Charles",
          "Dumas, Alexandre",
          "Dick, Philip K.",
          "Lovecraft, H. P. (Howard Phillips)",
          "Huxley, Aldous",
          "Churchill, Winston"
         ],
         "yaxis": "y",
         "z": [
          [
           9,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           6,
           3,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           1,
           8,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           5,
           3,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0
          ],
          [
           0,
           0,
           0,
           0,
           1,
           7,
           1,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           9,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           9,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           8,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           8,
           0,
           0,
           1,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           7,
           0,
           0,
           0,
           2,
           0,
           1
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           1,
           0,
           7,
           0,
           0,
           0,
           1,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           10,
           0,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           9,
           0
          ],
          [
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           0,
           1,
           0,
           9
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorscale": [
          [
           0,
           "rgb(209, 238, 234)"
          ],
          [
           0.16666666666666666,
           "rgb(168, 219, 217)"
          ],
          [
           0.3333333333333333,
           "rgb(133, 196, 201)"
          ],
          [
           0.5,
           "rgb(104, 171, 184)"
          ],
          [
           0.6666666666666666,
           "rgb(79, 144, 166)"
          ],
          [
           0.8333333333333334,
           "rgb(59, 115, 143)"
          ],
          [
           1,
           "rgb(42, 86, 116)"
          ]
         ],
         "showscale": false
        },
        "height": 800,
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 1000,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Predicted Label"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "True Label"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.imshow(confusion_matrix(y_test, results.predictions.argmax(axis=1)),\n",
    "                width=1000,\n",
    "                height=800,\n",
    "                text_auto=True,\n",
    "                labels=dict(x='Predicted Label',\n",
    "                            y='True Label'),\n",
    "                            x=select_authors,\n",
    "                            y=select_authors,\n",
    "                            color_continuous_scale='Teal'\n",
    "                            )\n",
    "\n",
    "fig.update(layout_coloraxis_showscale=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing New Text\n",
    "\n",
    "This part will ideally be in an app where any text can be uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "newtext = pd.DataFrame()\n",
    "\n",
    "for book_num, book_name in enumerate(['Lambda', 'Deathway']):\n",
    "        filepath = f'../data/{book_name} by Tomo Umer.txt'\n",
    "\n",
    "        with open(filepath, encoding = 'utf-8') as fi:\n",
    "                book = fi.read()\n",
    "        \n",
    "        tmp_text = pd.DataFrame({'id': f'TU{str(book_num).zfill(3)}',\n",
    "                                 'title': [book_name],\n",
    "                                 'author': 'Umer, Tomo',\n",
    "                                 'authorcentury': 21,\n",
    "                                 'book_content': [book]})\n",
    "\n",
    "        newtext = pd.concat([newtext, tmp_text], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookpart_list = []\n",
    "\n",
    "for i in range(n_parts):\n",
    "    # note: the +1s are there because I don't want the exact beginning, or the end of the book (there could be some junk there)\n",
    "    bookpart_list.append(newtext['book_content'].apply(lambda text: text[(i+1)* len(text) // (n_parts+1):]))\n",
    "\n",
    "# copy the library n_parts times, to concatenate with the split texts\n",
    "newtext_multi = pd.concat([newtext]*n_parts, ignore_index=True).drop(columns='book_content')\n",
    "\n",
    "# add the above parts of the text into a new column\n",
    "newtext_multi['book_part'] = pd.concat(bookpart_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd249cc51c144c5a3527abf9bfbdd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "newtext_ds = Dataset.from_dict({'text': newtext_multi['book_part']}) #, 'labels': y_test})\n",
    "\n",
    "tokenized_newtext_ds= newtext_ds.map(tokenize_function)\n",
    "tokenized_newtext_ds = tokenized_newtext_ds.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2431eb17a5bc4a8d873d2273f8a2b273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_results = trainer.predict(tokenized_newtext_ds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first book Lambda, second Deathway\n",
    "# newtext_multi['title'].unique()\n",
    "\n",
    "# to see what got predicted\n",
    "# new_results.predictions.argmax(axis=1)\n",
    "\n",
    "# book1_authors = set(new_results.predictions.argmax(axis=1)[::2])\n",
    "# book2_authors = set(new_results.predictions.argmax(axis=1)[1::2])\n",
    "\n",
    "# for author in book1_authors:\n",
    "#     print('Lambda is similar in writing to: ', num_to_authors[author])\n",
    "\n",
    "# for author in book2_authors:\n",
    "#     print('Deathway is similar in writing to: ', num_to_authors[author])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is needed for the strmlite app\n",
    "authors_df = pd.read_pickle('../data/select_authors.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_winners(model_predictions_max):\n",
    "    unique_num, counts = np.unique(model_predictions_max, return_counts=True)\n",
    "\n",
    "    unique_authors = [num_to_authors[unique] for unique in unique_num]\n",
    "\n",
    "    return pd.DataFrame({'most likely author': unique_authors, 'number of times':counts})\n",
    "\n",
    "# Note that the above is because I put two books in at once. for one at a time, I would define this function\n",
    "# to just give it predictions - like so\n",
    "# def compute_winners(model_predictions):\n",
    "#     unique_num, counts = np.unique(model_predictions.argmax(axis=1), return_counts=True)\n",
    "\n",
    "#     unique_authors = [num_to_authors[unique] for unique in unique_num]\n",
    "\n",
    "#     return pd.DataFrame({'most likely author': unique_authors, 'number of times':counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "book1_winners = compute_winners(new_results.predictions.argmax(axis=1)[::2])\n",
    "book2_winners = compute_winners(new_results.predictions.argmax(axis=1)[1::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>most likely author</th>\n",
       "      <th>number of times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dick, Philip K.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lovecraft, H. P. (Howard Phillips)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churchill, Winston</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   most likely author  number of times\n",
       "0                     Dick, Philip K.                7\n",
       "1  Lovecraft, H. P. (Howard Phillips)                2\n",
       "2                  Churchill, Winston                1"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book2_winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 21)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_results.predictions.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the results are logits. Need to use softmax to convert them to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.nn.functional as F\n",
    "# new_probabilities = F.softmax(new_results, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_probabilities = special.softmax(new_results.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_probabilities_df = pd.DataFrame(new_probabilities, columns=select_authors).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Homer                     1.35%\n",
       "Confucius                 2.65%\n",
       "Plato                     1.12%\n",
       "Cicero, Marcus Tullius    0.83%\n",
       "Seneca, Lucius Annaeus    1.12%\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_probabilities_df[0].head().map('{:.2%}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dick, Philip K.                       62.99%\n",
      "Lovecraft, H. P. (Howard Phillips)     6.13%\n",
      "Churchill, Winston                     3.09%\n",
      "Jefferson, Thomas                      3.06%\n",
      "Confucius                              2.65%\n",
      "Name: 0, dtype: object\n",
      "Dick, Philip K.                       37.36%\n",
      "Lovecraft, H. P. (Howard Phillips)     9.17%\n",
      "Jefferson, Thomas                      6.90%\n",
      "Churchill, Winston                     6.14%\n",
      "Doyle, Arthur Conan                    4.25%\n",
      "Name: 1, dtype: object\n",
      "Dick, Philip K.                       43.20%\n",
      "Jefferson, Thomas                      8.21%\n",
      "Churchill, Winston                     7.07%\n",
      "Lovecraft, H. P. (Howard Phillips)     4.71%\n",
      "Seneca, Lucius Annaeus                 4.27%\n",
      "Name: 2, dtype: object\n",
      "Dick, Philip K.                       56.11%\n",
      "Lovecraft, H. P. (Howard Phillips)     6.49%\n",
      "Churchill, Winston                     4.71%\n",
      "Twain, Mark                            3.84%\n",
      "Huxley, Aldous                         3.54%\n",
      "Name: 3, dtype: object\n",
      "Dick, Philip K.                       40.48%\n",
      "Lovecraft, H. P. (Howard Phillips)    11.40%\n",
      "Churchill, Winston                     6.52%\n",
      "Shakespeare, William                   5.05%\n",
      "Huxley, Aldous                         4.29%\n",
      "Name: 4, dtype: object\n",
      "Dick, Philip K.                       30.70%\n",
      "Lovecraft, H. P. (Howard Phillips)    11.56%\n",
      "Churchill, Winston                     9.64%\n",
      "Huxley, Aldous                         6.82%\n",
      "Jefferson, Thomas                      4.69%\n",
      "Name: 5, dtype: object\n",
      "Lovecraft, H. P. (Howard Phillips)    23.28%\n",
      "Dick, Philip K.                       23.13%\n",
      "Doyle, Arthur Conan                    6.36%\n",
      "Huxley, Aldous                         6.03%\n",
      "Dickens, Charles                       4.90%\n",
      "Name: 6, dtype: object\n",
      "Dick, Philip K.                       40.03%\n",
      "Lovecraft, H. P. (Howard Phillips)     8.65%\n",
      "Jefferson, Thomas                      6.85%\n",
      "Churchill, Winston                     5.83%\n",
      "Doyle, Arthur Conan                    3.47%\n",
      "Name: 7, dtype: object\n",
      "Dick, Philip K.                       53.81%\n",
      "Lovecraft, H. P. (Howard Phillips)     8.77%\n",
      "Churchill, Winston                     4.36%\n",
      "Shakespeare, William                   3.52%\n",
      "Huxley, Aldous                         3.37%\n",
      "Name: 8, dtype: object\n",
      "Lovecraft, H. P. (Howard Phillips)    25.07%\n",
      "Huxley, Aldous                        16.94%\n",
      "Dick, Philip K.                        7.38%\n",
      "Churchill, Winston                     6.74%\n",
      "Dickens, Charles                       5.17%\n",
      "Name: 9, dtype: object\n",
      "Dick, Philip K.                       42.18%\n",
      "Lovecraft, H. P. (Howard Phillips)    11.22%\n",
      "Doyle, Arthur Conan                    6.15%\n",
      "Confucius                              4.90%\n",
      "Shakespeare, William                   3.96%\n",
      "Name: 10, dtype: object\n",
      "Churchill, Winston        12.59%\n",
      "Dick, Philip K.           12.32%\n",
      "Molière                    8.44%\n",
      "Jefferson, Thomas          7.23%\n",
      "Seneca, Lucius Annaeus     6.64%\n",
      "Name: 11, dtype: object\n",
      "Dick, Philip K.                       41.88%\n",
      "Lovecraft, H. P. (Howard Phillips)    10.22%\n",
      "Churchill, Winston                     4.97%\n",
      "Shakespeare, William                   4.72%\n",
      "Doyle, Arthur Conan                    3.96%\n",
      "Name: 12, dtype: object\n",
      "Dick, Philip K.                       24.27%\n",
      "Lovecraft, H. P. (Howard Phillips)    16.38%\n",
      "Churchill, Winston                     8.48%\n",
      "Huxley, Aldous                         6.21%\n",
      "Doyle, Arthur Conan                    5.55%\n",
      "Name: 13, dtype: object\n",
      "Dick, Philip K.                       59.27%\n",
      "Lovecraft, H. P. (Howard Phillips)     5.73%\n",
      "Shakespeare, William                   3.93%\n",
      "Confucius                              3.62%\n",
      "Churchill, Winston                     3.28%\n",
      "Name: 14, dtype: object\n",
      "Dick, Philip K.                       43.99%\n",
      "Jefferson, Thomas                      6.77%\n",
      "Churchill, Winston                     6.08%\n",
      "Lovecraft, H. P. (Howard Phillips)     5.72%\n",
      "Doyle, Arthur Conan                    4.09%\n",
      "Name: 15, dtype: object\n",
      "Dick, Philip K.                       29.68%\n",
      "Lovecraft, H. P. (Howard Phillips)    12.80%\n",
      "Shakespeare, William                   7.03%\n",
      "Doyle, Arthur Conan                    6.89%\n",
      "Huxley, Aldous                         6.05%\n",
      "Name: 16, dtype: object\n",
      "Dick, Philip K.                       45.13%\n",
      "Lovecraft, H. P. (Howard Phillips)    11.79%\n",
      "Churchill, Winston                     6.44%\n",
      "Huxley, Aldous                         4.15%\n",
      "Jefferson, Thomas                      3.91%\n",
      "Name: 17, dtype: object\n",
      "Dick, Philip K.                       34.40%\n",
      "Lovecraft, H. P. (Howard Phillips)     9.43%\n",
      "Churchill, Winston                     7.34%\n",
      "Shakespeare, William                   6.02%\n",
      "Doyle, Arthur Conan                    5.97%\n",
      "Name: 18, dtype: object\n",
      "Lovecraft, H. P. (Howard Phillips)    23.91%\n",
      "Dick, Philip K.                       11.37%\n",
      "Huxley, Aldous                        10.41%\n",
      "Doyle, Arthur Conan                    8.25%\n",
      "Churchill, Winston                     7.60%\n",
      "Name: 19, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for column in new_probabilities_df:\n",
    "    print(new_probabilities_df[column].sort_values(ascending=False).head().map('{:.2%}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_books = pd.concat([newtext_multi ,pd.DataFrame(new_probabilities, columns=select_authors)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>authorcentury</th>\n",
       "      <th>book_part</th>\n",
       "      <th>Homer</th>\n",
       "      <th>Confucius</th>\n",
       "      <th>Plato</th>\n",
       "      <th>Cicero, Marcus Tullius</th>\n",
       "      <th>Seneca, Lucius Annaeus</th>\n",
       "      <th>...</th>\n",
       "      <th>Defoe, Daniel</th>\n",
       "      <th>Austen, Jane</th>\n",
       "      <th>Twain, Mark</th>\n",
       "      <th>Doyle, Arthur Conan</th>\n",
       "      <th>Dickens, Charles</th>\n",
       "      <th>Dumas, Alexandre</th>\n",
       "      <th>Dick, Philip K.</th>\n",
       "      <th>Lovecraft, H. P. (Howard Phillips)</th>\n",
       "      <th>Huxley, Aldous</th>\n",
       "      <th>Churchill, Winston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>in the world left in her at that precise momen...</td>\n",
       "      <td>0.014533</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.022319</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014419</td>\n",
       "      <td>0.041128</td>\n",
       "      <td>0.029623</td>\n",
       "      <td>0.042460</td>\n",
       "      <td>0.017873</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>0.373612</td>\n",
       "      <td>0.091680</td>\n",
       "      <td>0.034011</td>\n",
       "      <td>0.061430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>rily lie down. “Just a quick break,” she told ...</td>\n",
       "      <td>0.014873</td>\n",
       "      <td>0.017995</td>\n",
       "      <td>0.008333</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.020263</td>\n",
       "      <td>0.038441</td>\n",
       "      <td>0.017389</td>\n",
       "      <td>0.011713</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.561090</td>\n",
       "      <td>0.064924</td>\n",
       "      <td>0.035425</td>\n",
       "      <td>0.047127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>ing up with her laundry.\\nAt the very least, h...</td>\n",
       "      <td>0.012432</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.012930</td>\n",
       "      <td>0.013248</td>\n",
       "      <td>0.041439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>0.036448</td>\n",
       "      <td>0.046341</td>\n",
       "      <td>0.033930</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.023936</td>\n",
       "      <td>0.307046</td>\n",
       "      <td>0.115609</td>\n",
       "      <td>0.068246</td>\n",
       "      <td>0.096436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>t to miss this party of yours.”\\nThat last com...</td>\n",
       "      <td>0.018059</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.017539</td>\n",
       "      <td>0.018849</td>\n",
       "      <td>0.031634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014582</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>0.034743</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>0.400278</td>\n",
       "      <td>0.086474</td>\n",
       "      <td>0.033554</td>\n",
       "      <td>0.058300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TU001</td>\n",
       "      <td>Deathway</td>\n",
       "      <td>Umer, Tomo</td>\n",
       "      <td>21</td>\n",
       "      <td>ing mind games with her on this particular Thu...</td>\n",
       "      <td>0.010882</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.018298</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.031091</td>\n",
       "      <td>0.039341</td>\n",
       "      <td>0.047925</td>\n",
       "      <td>0.051747</td>\n",
       "      <td>0.030690</td>\n",
       "      <td>0.073750</td>\n",
       "      <td>0.250739</td>\n",
       "      <td>0.169421</td>\n",
       "      <td>0.067420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id     title      author  authorcentury  \\\n",
       "1  TU001  Deathway  Umer, Tomo             21   \n",
       "3  TU001  Deathway  Umer, Tomo             21   \n",
       "5  TU001  Deathway  Umer, Tomo             21   \n",
       "7  TU001  Deathway  Umer, Tomo             21   \n",
       "9  TU001  Deathway  Umer, Tomo             21   \n",
       "\n",
       "                                           book_part     Homer  Confucius  \\\n",
       "1  in the world left in her at that precise momen...  0.014533   0.021038   \n",
       "3  rily lie down. “Just a quick break,” she told ...  0.014873   0.017995   \n",
       "5  ing up with her laundry.\\nAt the very least, h...  0.012432   0.015743   \n",
       "7  t to miss this party of yours.”\\nThat last com...  0.018059   0.020753   \n",
       "9  ing mind games with her on this particular Thu...  0.010882   0.020914   \n",
       "\n",
       "      Plato  Cicero, Marcus Tullius  Seneca, Lucius Annaeus  ...  \\\n",
       "1  0.022319                0.021039                0.034507  ...   \n",
       "3  0.008333                0.008065                0.024003  ...   \n",
       "5  0.012930                0.013248                0.041439  ...   \n",
       "7  0.017539                0.018849                0.031634  ...   \n",
       "9  0.018298                0.011226                0.015100  ...   \n",
       "\n",
       "   Defoe, Daniel  Austen, Jane  Twain, Mark  Doyle, Arthur Conan  \\\n",
       "1       0.014419      0.041128     0.029623             0.042460   \n",
       "3       0.006739      0.020263     0.038441             0.017389   \n",
       "5       0.009528      0.036448     0.046341             0.033930   \n",
       "7       0.014582      0.028135     0.023656             0.034743   \n",
       "9       0.009344      0.031091     0.039341             0.047925   \n",
       "\n",
       "   Dickens, Charles  Dumas, Alexandre  Dick, Philip K.  \\\n",
       "1          0.017873          0.015319         0.373612   \n",
       "3          0.011713          0.012322         0.561090   \n",
       "5          0.015570          0.023936         0.307046   \n",
       "7          0.015124          0.017934         0.400278   \n",
       "9          0.051747          0.030690         0.073750   \n",
       "\n",
       "   Lovecraft, H. P. (Howard Phillips)  Huxley, Aldous  Churchill, Winston  \n",
       "1                            0.091680        0.034011            0.061430  \n",
       "3                            0.064924        0.035425            0.047127  \n",
       "5                            0.115609        0.068246            0.096436  \n",
       "7                            0.086474        0.033554            0.058300  \n",
       "9                            0.250739        0.169421            0.067420  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#similar_books.loc[similar_books['title'] == 'Lambda'].head()\n",
    "similar_books.loc[similar_books['title'] == 'Deathway'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_books = (\n",
    "    similar_books\n",
    "        .drop(columns=['id', 'authorcentury', 'book_part', 'author'])\n",
    "        .groupby('title')\n",
    "        .mean()\n",
    "        .pivot_table(columns='title')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dick, Philip K.                       2.169794\n",
      "Lovecraft, H. P. (Howard Phillips)    1.304179\n",
      "Churchill, Winston                    0.888144\n",
      "Huxley, Aldous                        0.590142\n",
      "Jefferson, Thomas                     0.393259\n",
      "Name: Deathway, dtype: float32\n",
      "--------\n",
      "Dick, Philip K.                       2.726228\n",
      "Lovecraft, H. P. (Howard Phillips)    1.243493\n",
      "Churchill, Winston                    0.499763\n",
      "Doyle, Arthur Conan                   0.401514\n",
      "Shakespeare, William                  0.356518\n",
      "Name: Lambda, dtype: float32\n"
     ]
    }
   ],
   "source": [
    "print(similar_books.sort_values(by='Deathway', ascending=False)['Deathway'].head())\n",
    "print('--------')\n",
    "print(similar_books.sort_values(by='Lambda', ascending=False)['Lambda'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface_ds6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
